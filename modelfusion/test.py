from transformers import BertTokenizer, BertModel
from transformers import AutoTokenizer, AutoModelForMaskedLM
import re

if __name__ == '__main__':
    # tokenizer = BertTokenizer.from_pretrained("hfl/chinese-bert-wwm-ext")
    # model = BertModel.from_pretrained("hfl/chinese-bert-wwm-ext")
    # text = "#æµ·æ²§åŠé©¬#12.10ç›¸çº¦å¦é—¨æˆ‘ä»¬ä¸è§ä¸æ•£ğŸ¼@å¦é—¨å›½é™…é©¬æ‹‰æ¾èµ›|å¦é—¨Â·å¦é—¨..."
    # print(tokenizer.tokenize(text))
    str1 = '#å¤©æ´¥å¡˜æ²½å¤§çˆ†ç‚¸#å¦ˆçš„ï¼Œä¸­å›½é¢†å¯¼éƒ½æ˜¯åƒå¤§ä¾¿å—'
    t = re.findall("#[^#]+#", str1)
    print(t)
    str2 = 'ã€äº‘å—è¥¿åŒç‰ˆçº³å·æ™¯æ´ªå¸‚å‘ç”Ÿ4.9çº§åœ°éœ‡éœ‡æºæ·±åº¦12åƒç±³ã€‘@ä¸­å›½åœ°éœ‡å°ç½‘æ­£å¼æµ‹å®š'

    # input_ids = torch.tensor(tokenizer.encode(text)).unsqueeze(0)
    # outputs = model(input_ids)
    # sequence_output = outputs[0]
    # pooled_output = outputs[1]
    # print(sequence_output)
